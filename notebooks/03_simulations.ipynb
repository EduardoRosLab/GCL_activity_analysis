{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELLS SPIKES GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating spikes of MFs and GrCs using the EDLUT simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from pyedlut import simulation_wrapper as pyedlut\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### PARAMETERS ###########################\n",
    "######### 01_anatomical_model_generation #################\n",
    "\n",
    "seed = 3 # seed for the generation of cells positions\n",
    "\n",
    "########## 02_input_patterns_generation ##################\n",
    "\n",
    "## Spatial correlation between MFs \n",
    "sigma = 5 \n",
    "\n",
    "## List of MF active fractions that will be used \n",
    "f_mf = np.linspace(.05, 0.95, 10)\n",
    "\n",
    "## Number of patterns to be simulate for each\n",
    "## MF active fraction \n",
    "num_patterns = 640\n",
    "\n",
    "############## 03_simulations ############################\n",
    "\n",
    "## Poisson generator seed that will be used for MFs spikes \n",
    "## Initializing it to the same seed as for cell posisions\n",
    "poisson_seed = seed\n",
    "\n",
    "## List of noises fractions to be introduced in the set \n",
    "## of MFs patterns\n",
    "noises = [0.4]\n",
    "\n",
    "## Number of presentations/samples for each pattern\n",
    "## Important parameter when noise != 0.0\n",
    "n_seeds = 5 \n",
    "\n",
    "## Duration of each simulated pattern \n",
    "duration_pattern = 0.080 ## 80 ms\n",
    "\n",
    "## Interval used to count spikes \n",
    "## The first 10 ms will be discarded\n",
    "interval = 0.070 ## 70 ms\n",
    "\n",
    "\n",
    "###### Synaptic weights ######\n",
    "\n",
    "## Total synaptic weight that reaches each GrC from MFs\n",
    "mf_grc_w = 4.00\n",
    "\n",
    "## Number of MFs connected to each GrC\n",
    "## Should not be changed\n",
    "n_mf_grc = 4 \n",
    "\n",
    "## List of synaptic weights to simulate from MF to GoC\n",
    "mf_goc_weights = [0.0, 0.10, 0.20]\n",
    "\n",
    "## List of synaptic weights to simulate from GrC to GoC\n",
    "grc_goc_weights = [0.01]\n",
    "\n",
    "# Inhibitory weight in GoC to GrC synapsis\n",
    "## Should not be to larger or the simulator crashes \n",
    "goc_grc_w = 0.50 \n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to count the number of spikes per cell and per pattern (step)\n",
    "\n",
    "def spikes_count(oi, ot, t_step, t_lower):\n",
    "\n",
    "    ## receives cells spiking times (ot) and their indexes (oi)\n",
    "    ## receives duration of the pattern (t_step) and the time discarded from the pattern (t_lower)\n",
    "    ## retrieves spikes count per pattern and per cell\n",
    "        \n",
    "    total_rows = n_inputs + n_hidden_neurons + n_outputs # neurons number \n",
    "    total_columns = int(total_simulation_time / t_step) # intervals number  \n",
    "    spikes_count = np.zeros((total_rows, total_columns))\n",
    "\n",
    "    for i in range(len(oi)):\n",
    "        col = int(ot[i]//t_step)\n",
    "        t = ot[i] - col*t_step\n",
    "\n",
    "        if (t > t_lower):\n",
    "            spikes_count[oi[i]][col] += 1\n",
    "\n",
    "    return spikes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading structure data \n",
    "sys.path.insert(1, '../data/structure')\n",
    "DATA_DIR = '../data/structure'\n",
    "SEED_DATA_DIR = os.path.join(DATA_DIR, 'seed' + str(seed))\n",
    "\n",
    "## For each noise from list of noises to be applied\n",
    "for noise in noises:\n",
    "    \n",
    "    ## For each GrC - GoC weight to be simulated \n",
    "    for grc_goc_w in grc_goc_weights:\n",
    "\n",
    "        ## For each MF - GoC weight to be simulated\n",
    "        for mf_goc_w in mf_goc_weights:\n",
    "            \n",
    "            ## For each MF active fraction \n",
    "            for elem in f_mf:\n",
    "\n",
    "                ## Loading anatomical model information \n",
    "                with open(SEED_DATA_DIR + '/glos.npy', 'rb') as f:\n",
    "                    glos = np.load(f)\n",
    "                with open(SEED_DATA_DIR + '/grcs.npy', 'rb') as f:\n",
    "                    grcs = np.load(f)\n",
    "                with open(SEED_DATA_DIR + '/gocs.npy', 'rb') as f:\n",
    "                    gocs = np.load(f)    \n",
    "                with open(SEED_DATA_DIR + '/conn_mat_glos_to_grc.npy', 'rb') as f:\n",
    "                    conn_mat_glos_to_grc = np.load(f)    \n",
    "                with open(SEED_DATA_DIR + '/conn_mat_glos_to_goc.npy', 'rb') as f:\n",
    "                    conn_mat_glos_to_goc = np.load(f)\n",
    "                with open(SEED_DATA_DIR + '/conn_mat_grcs_to_goc.npy', 'rb') as f:\n",
    "                    conn_mat_grcs_to_goc = np.load(f)\n",
    "                with open(SEED_DATA_DIR + '/conn_mat_goc_to_grcs.npy', 'rb') as f:\n",
    "                    conn_mat_goc_to_grcs = np.load(f) \n",
    "\n",
    "\n",
    "                ## Total active MF fraction of the simulation\n",
    "                fraction = elem \n",
    "\n",
    "                ## Number of cells for each population\n",
    "                n_inputs = glos.shape[0]\n",
    "                n_hidden_neurons = grcs.shape[0]\n",
    "                n_outputs = gocs.shape[0]\n",
    "\n",
    "                ## Setting to 0 this synapses momentarily because we have to previously introduce noise in \n",
    "                ## the MF patterns\n",
    "                mf_grc_w_0 = 0.00 \n",
    "\n",
    "                ## Time steps in seconds \n",
    "                edlut_time_step = 5e-4\n",
    "                \n",
    "                ## Simulation time in seconds\n",
    "                stop_simulation_at = num_patterns * duration_pattern\n",
    "            \n",
    "                # Defining LIF neuron parameters\n",
    "                default_neuron_params = {\n",
    "                    'c_m': 250.0,\n",
    "                    'e_exc': 0.0,\n",
    "                    'e_inh': -85.0,\n",
    "                    'e_leak': -65.0,\n",
    "                    'g_leak': 25.0,\n",
    "                    'tau_exc': 5.0,\n",
    "                    'tau_inh': 10.0,\n",
    "                    'tau_nmda': 20.0,\n",
    "                    'tau_ref': 1.0,\n",
    "                    'v_thr': -40.0,\n",
    "                    'int_meth': None,\n",
    "                }\n",
    "\n",
    "\n",
    "                poisson_generator_params = {\n",
    "                    'frequency': 50.0,\n",
    "                }\n",
    "\n",
    "                hidden_neuron_params = { \n",
    "                    **default_neuron_params,\n",
    "                    'c_m': 2.0,\n",
    "                    'e_exc': 0.0,\n",
    "                    'e_inh': -65.0,\n",
    "                    'e_leak': -65.0,\n",
    "                    'g_leak': 0.2,\n",
    "                    'tau_exc': 0.5,\n",
    "                    'tau_inh': 10.0,\n",
    "                    'tau_nmda': 40.0,\n",
    "                    'tau_ref': 1.5,\n",
    "                    'v_thr': -40.0,   \n",
    "                }\n",
    "\n",
    "                # Parámetros de las GOC\n",
    "                output_neuron_params = {\n",
    "                    **default_neuron_params,        \n",
    "                    'c_m': 50.0,\n",
    "                    'g_leak': 10.0,\n",
    "                    'v_thr': -50.0,\n",
    "                } \n",
    "\n",
    "                # Parámetros de las sinapsis\n",
    "                default_synapse_params = {\n",
    "                    'weight': 0.006,    #Initial weight\n",
    "                    'max_weight': 0.020, #Max weight\n",
    "                    'type': 0,\n",
    "                    'delay': 0.001,\n",
    "                    'wchange': -1,\n",
    "                    'trigger_wchange': -1,\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ####################### SIMULATION 0 ##############################################################################################\n",
    "                ## In this initial simulation, only MFs spikes will be generated using the raw patterns without noise\n",
    "                \n",
    "                ## Loading input patterns\n",
    "                sys.path.insert(1, '../data/input_patterns')\n",
    "                with open('../data/input_patterns/seed'+ str(seed) + '/mf_activity_f_mf_' + str(fraction) + '_s_' + str(sigma) + '.npy', 'rb') as f:       \n",
    "                    mf_activity = np.load(f)\n",
    "\n",
    "                ## Preparing activity dataset \n",
    "                mf_activity = mf_activity[0].T\n",
    "                mf_activity = mf_activity[:,:num_patterns] ## taking only the number of patterns we want to simulate\n",
    "\n",
    "                \n",
    "                ## Defining binary input patterns\n",
    "                input_patterns = np.zeros((n_inputs, num_patterns))                \n",
    "                input_patterns = np.tile(mf_activity, reps = 1)\n",
    "\n",
    "                ## Declaring the simulation object\n",
    "                simulation = pyedlut.PySimulation_API()\n",
    "                ## Initializing Poisson generator seed \n",
    "                simulation.SetRandomGeneratorSeed(poisson_seed)\n",
    "\n",
    "                ## Defining the integration method\n",
    "                integration_method = pyedlut.PyModelDescription(model_name='RK4', params_dict={'step': edlut_time_step})\n",
    "                default_neuron_params['int_meth'] = integration_method\n",
    "                hidden_neuron_params['int_meth'] = integration_method\n",
    "\n",
    "                ## Defining synapsis\n",
    "                mf_grc_synapse_params = {**default_synapse_params,'weight': mf_grc_w_0/n_mf_grc,'max_weight': mf_grc_w_0/n_mf_grc, 'type': 0}\n",
    "\n",
    "                ## Creating neuron layers\n",
    "                \n",
    "                # MFs layer\n",
    "                input_poisson_generator_layer = simulation.AddNeuronLayer(\n",
    "                    num_neurons = n_inputs,\n",
    "                    model_name = 'PoissonGeneratorDeviceVector',\n",
    "                    param_dict = poisson_generator_params,\n",
    "                    log_activity = False,\n",
    "                    output_activity = True\n",
    "                )\n",
    "\n",
    "                # GrCs layer\n",
    "                hidden_layer = simulation.AddNeuronLayer(\n",
    "                    num_neurons = n_hidden_neurons,\n",
    "                    model_name = 'LIFTimeDrivenModel',\n",
    "                    param_dict = hidden_neuron_params,\n",
    "                    log_activity = False,\n",
    "                    output_activity = False\n",
    "                )\n",
    "\n",
    "                #################### Connections from MF to GRC ################################\n",
    "\n",
    "                sources2 = []\n",
    "                hidden2 = []\n",
    "\n",
    "                for i in range(conn_mat_glos_to_grc.shape[1]): \n",
    "                    srcs = np.where(conn_mat_glos_to_grc[:,i] == 1)[0].tolist()\n",
    "                    sources2.append(srcs)\n",
    "                    hid = i + n_inputs\n",
    "                    hidden2.append([hid]*len(srcs))\n",
    "\n",
    "\n",
    "                sources = []\n",
    "                hidden = []\n",
    "\n",
    "                ## Saving the indexes of all the MFs connected to each GrC\n",
    "                for sublist in sources2:\n",
    "                    for item in sublist:\n",
    "                        sources.append(item)\n",
    "\n",
    "                for sublist in hidden2:\n",
    "                    for item in sublist:\n",
    "                        hidden.append(item)\n",
    "\n",
    "                # Defining MF -> GrC excitatory synapsis \n",
    "                weights = simulation.AddSynapticLayer(\n",
    "                source_list = sources,\n",
    "                target_list = hidden,\n",
    "                param_dict = mf_grc_synapse_params,\n",
    "                )    \n",
    "                \n",
    "                ## Initializing simulation\n",
    "                simulation.Initialize()\n",
    "\n",
    "                ## Setting PoissonGeneratorDeviceVector\n",
    "                ## Firing rate frequency for MFs will be 50.0 Hz\n",
    "\n",
    "                for i in range(n_inputs):\n",
    "\n",
    "                    poisson_params = {'frequency': 50.0 * input_patterns[i, 0]} # noise for MFs in the inner cube \n",
    "                    simulation.SetSpecificNeuronParams(input_poisson_generator_layer[i], poisson_params)\n",
    "\n",
    "                ## Running the simulation step-by-step (pattern by pattern)\n",
    "\n",
    "                total_simulation_time = stop_simulation_at\n",
    "                simulation_bin = duration_pattern\n",
    "\n",
    "                j = 1\n",
    "                for sim_time in np.arange(0.0 + simulation_bin, total_simulation_time + simulation_bin - 0.000001, simulation_bin):\n",
    "\n",
    "                    simulation.RunSimulation(sim_time)\n",
    "\n",
    "                    if j < (num_patterns):\n",
    "\n",
    "                        # Updating all poissons every timebin\n",
    "                        for i in range(n_inputs):\n",
    "                                poisson_params = {'frequency': 50.0 * input_patterns[i,j]}\n",
    "                                simulation.SetSpecificNeuronParams(input_poisson_generator_layer[i], poisson_params)\n",
    "\n",
    "                    j += 1\n",
    "\n",
    "                # Retrieving output spike activity\n",
    "                output_times, output_index = simulation.GetSpikeActivity()\n",
    "                ot0 = np.array(output_times) ## spikes times\n",
    "                oi0 = np.array(output_index) ## spikes indexes\n",
    "\n",
    "                ## Initializing noise seed\n",
    "                seed_noise = 0\n",
    "\n",
    "                for k in range(n_seeds):\n",
    "                    \n",
    "                    ####################### SIMULATION K ##############################################################################################\n",
    "                    \n",
    "                    ## Now that the original MFs spikes have been generated, \n",
    "                    ## new spikes trains will be generated for each pattern\n",
    "                \n",
    "                    with open('../data/input_patterns/seed'+ str(seed) + '/mf_activity_f_mf_' + str(fraction) + '_s_' + str(sigma) + '.npy', 'rb') as f:       \n",
    "                        mf_activity = np.load(f)\n",
    "\n",
    "                    ## Preparing activity dataset \n",
    "                    mf_activity = mf_activity[0].T\n",
    "                    mf_activity = mf_activity[:,:num_patterns] ## taking only the number of patterns we want to simulate\n",
    "\n",
    "                    ## Input patterns (binary vectors)\n",
    "                    input_patterns = np.zeros((n_inputs, num_patterns))\n",
    "\n",
    "                    ## Declaring the simulation object\n",
    "                    simulation = pyedlut.PySimulation_API()\n",
    "                    ## Updating the poisson seed (very important in order to have new spikes trains)\n",
    "                    simulation.SetRandomGeneratorSeed(k + poisson_seed + 1)\n",
    "\n",
    "                    ## Defining the integration method\n",
    "                    integration_method = pyedlut.PyModelDescription(model_name='RK4', params_dict={'step': edlut_time_step})\n",
    "                    default_neuron_params['int_meth'] = integration_method\n",
    "                    hidden_neuron_params['int_meth'] = integration_method\n",
    "\n",
    "                    ## Defining synapsis\n",
    "                    mf_grc_synapse_params = {**default_synapse_params,'weight': mf_grc_w_0/n_mf_grc,'max_weight': mf_grc_w_0/n_mf_grc, 'type': 0}\n",
    "\n",
    "                    ## Creating neuron layers\n",
    "\n",
    "                    # MFs layer\n",
    "                    input_poisson_generator_layer = simulation.AddNeuronLayer(\n",
    "                        num_neurons = n_inputs,\n",
    "                        model_name = 'PoissonGeneratorDeviceVector',\n",
    "                        param_dict = poisson_generator_params,\n",
    "                        log_activity = False,\n",
    "                        output_activity = True\n",
    "                    )    \n",
    "\n",
    "                    # GRCs layer\n",
    "                    hidden_layer = simulation.AddNeuronLayer(\n",
    "                        num_neurons = n_hidden_neurons,\n",
    "                        model_name = 'LIFTimeDrivenModel',\n",
    "                        param_dict = hidden_neuron_params,\n",
    "                        log_activity = False,\n",
    "                        output_activity = False\n",
    "                    )\n",
    "\n",
    "\n",
    "                    #################### Connections from MF to GRC ################################\n",
    "\n",
    "                    sources2 = []\n",
    "                    hidden2 = []\n",
    "\n",
    "                    for i in range(conn_mat_glos_to_grc.shape[1]): \n",
    "                        srcs = np.where(conn_mat_glos_to_grc[:,i] == 1)[0].tolist()\n",
    "                        sources2.append(srcs)\n",
    "                        hid = i + n_inputs\n",
    "                        hidden2.append([hid]*len(srcs))\n",
    "\n",
    "\n",
    "                    sources = []\n",
    "                    hidden = []\n",
    "\n",
    "                    ## Saving the indexes of all the MFs connected to each GrC\n",
    "                    for sublist in sources2:\n",
    "                        for item in sublist:\n",
    "                            sources.append(item)\n",
    "\n",
    "                    for sublist in hidden2:\n",
    "                        for item in sublist:\n",
    "                            hidden.append(item)\n",
    "\n",
    "                    ## MF -> GrC excitatory synapsis \n",
    "                    weights = simulation.AddSynapticLayer(\n",
    "                    source_list = sources,\n",
    "                    target_list = hidden,\n",
    "                    param_dict = mf_grc_synapse_params,\n",
    "                    )    \n",
    "\n",
    "                    \n",
    "                    ## Initializing simulation\n",
    "                    simulation.Initialize()\n",
    "\n",
    "                    # Activating all MFs in order to generate spikes in all of them\n",
    "                    for i in range(n_inputs):\n",
    "                            input_patterns[i,:] = 1.0\n",
    "\n",
    "\n",
    "                    ## Setting PoissonGeneratorDeviceVector\n",
    "                    ## Firing rate frequency for MFs will be 50.0 Hz\n",
    "\n",
    "                    for i in range(n_inputs):\n",
    "                            \n",
    "                        poisson_params = {'frequency': 50.0 * input_patterns[i, 0]} # noise for MFs in the inner cube \n",
    "                        simulation.SetSpecificNeuronParams(input_poisson_generator_layer[i], poisson_params)\n",
    "\n",
    "                    # Running the simulation step-by-step (pattern by pattern)\n",
    "\n",
    "                    total_simulation_time = stop_simulation_at\n",
    "                    simulation_bin = duration_pattern\n",
    "\n",
    "                    j = 1\n",
    "                    for sim_time in np.arange(0.0 + simulation_bin, total_simulation_time + simulation_bin - 0.000001, simulation_bin):\n",
    "\n",
    "                        simulation.RunSimulation(sim_time)\n",
    "\n",
    "                        if j < (num_patterns):\n",
    "\n",
    "                            # Updating all poissons every timebin\n",
    "                            for i in range(n_inputs):\n",
    "                                poisson_params = {'frequency': 50.0 * input_patterns[i,j]}\n",
    "                                simulation.SetSpecificNeuronParams(input_poisson_generator_layer[i], poisson_params)\n",
    "\n",
    "                        j += 1\n",
    "\n",
    "\n",
    "                    \n",
    "                    # Retrieving output spike activity\n",
    "                    output_times, output_index = simulation.GetSpikeActivity()\n",
    "                    ot_k = np.array(output_times)\n",
    "                    oi_k = np.array(output_index)\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    #########################################################################################\n",
    "                    ### MERGING OF S0 AND S_K ###############################################################\n",
    "                    #########################################################################################\n",
    "\n",
    "                    ## Now, given the chosen noise percentage, the activity of noisy MFs will be replace\n",
    "                    ## from their original spikes to the ones generated in the new spikes trains\n",
    "                    ## The rest of connections will also be generated\n",
    "\n",
    "                    print(\"\")\n",
    "                    print('Sigma: ' + str(sigma))\n",
    "                    print('f_mf: ' + str(fraction))\n",
    "                    print('MF - GOC weight: ' + str(mf_goc_w))\n",
    "                    print('GRC - GOC weight: ' + str(grc_goc_w))\n",
    "                    print(\"\")\n",
    "\n",
    "\n",
    "                    ## Generating directories for spikes count\n",
    "                    os.makedirs('../data/spikes/seed' + str(seed) \n",
    "                                + '/sigma_' + str(sigma) \n",
    "                                + '/noise_' + str(noise)\n",
    "                                + '/grc'\n",
    "                                + '/mf_grc_' + str(mf_grc_w)\n",
    "                                + '/mf_goc_w_' + str(mf_goc_w)\n",
    "                                + '/goc_grc_w_' + str(goc_grc_w)\n",
    "                                + '/grc_goc_w_' + str(grc_goc_w)\n",
    "                                + '/f_mf_' + str(fraction) , exist_ok=True)\n",
    "\n",
    "                    os.makedirs('../data/spikes/seed' + str(seed) \n",
    "                                + '/sigma_' + str(sigma) \n",
    "                                + '/noise_' + str(noise)\n",
    "                                + '/mf'\n",
    "                                + '/f_mf_' + str(fraction) , exist_ok=True)\n",
    "\n",
    "\n",
    "                    ## Declaring the simulation object\n",
    "                    simulation = pyedlut.PySimulation_API()\n",
    "\n",
    "                    ## Defining the integration method\n",
    "                    integration_method = pyedlut.PyModelDescription(model_name='RK4', params_dict={'step': edlut_time_step})\n",
    "                    default_neuron_params['int_meth'] = integration_method\n",
    "                    hidden_neuron_params['int_meth'] = integration_method\n",
    "                    output_neuron_params['int_meth'] = integration_method\n",
    "\n",
    "                    ## Defining the synapses parameters\n",
    "                    mf_grc_synapse_params = {**default_synapse_params,'weight': mf_grc_w/n_mf_grc,'max_weight': mf_grc_w/n_mf_grc, 'type': 0}\n",
    "                    mf_goc_synapse_params = {**default_synapse_params,'weight': mf_goc_w,'max_weight': mf_goc_w, 'type': 0}\n",
    "                    grc_goc_synapse_params = {**default_synapse_params,'weight': grc_goc_w,'max_weight': grc_goc_w, 'type': 0}\n",
    "                    goc_grc_synapse_params = {**default_synapse_params,'weight': goc_grc_w,'max_weight': goc_grc_w, 'type': 1}\n",
    "\n",
    "                    ## Creating neuron layers \n",
    "\n",
    "                    # MFs layer\n",
    "                    input_poisson_generator_layer = simulation.AddNeuronLayer(\n",
    "                        num_neurons = n_inputs,\n",
    "                        model_name = 'InputSpikeNeuronModel',\n",
    "                        param_dict = {},\n",
    "                        log_activity = False,\n",
    "                        output_activity = True\n",
    "                    )\n",
    "\n",
    "                    # GRCs layer\n",
    "                    hidden_layer = simulation.AddNeuronLayer(\n",
    "                        num_neurons = n_hidden_neurons,\n",
    "                        model_name = 'LIFTimeDrivenModel',\n",
    "                        param_dict = hidden_neuron_params,\n",
    "                        log_activity = False,\n",
    "                        output_activity = True\n",
    "                    )\n",
    "\n",
    "                    # GoCs layer\n",
    "                    output_layer = simulation.AddNeuronLayer(\n",
    "                        num_neurons = n_outputs,\n",
    "                        model_name = 'LIFTimeDrivenModel',\n",
    "                        param_dict = output_neuron_params,\n",
    "                        log_activity = False,\n",
    "                        output_activity = True\n",
    "                    )\n",
    "\n",
    "                    #################### Connections from MF to GRC ################################\n",
    "\n",
    "                    sources2 = []\n",
    "                    hidden2 = []\n",
    "\n",
    "                    for i in range(conn_mat_glos_to_grc.shape[1]): \n",
    "                        srcs = np.where(conn_mat_glos_to_grc[:,i] == 1)[0].tolist()\n",
    "                        sources2.append(srcs)\n",
    "                        hid = i + n_inputs\n",
    "                        hidden2.append([hid]*len(srcs))\n",
    "\n",
    "\n",
    "                    sources = []\n",
    "                    hidden = []\n",
    "\n",
    "                    ## Saving the indexes of all the MFs connected to each GrC\n",
    "                    for sublist in sources2:\n",
    "                        for item in sublist:\n",
    "                            sources.append(item)\n",
    "\n",
    "                    for sublist in hidden2:\n",
    "                        for item in sublist:\n",
    "                            hidden.append(item)\n",
    "\n",
    "                    # MF -> GrC excitatory synapsis \n",
    "                    weights = simulation.AddSynapticLayer(\n",
    "                    source_list = sources,\n",
    "                    target_list = hidden,\n",
    "                    param_dict = mf_grc_synapse_params,\n",
    "                    )    \n",
    "\n",
    "                    ######################## Connections from MF to GoC ###############################\n",
    "\n",
    "                    sources2 = []\n",
    "                    targets2 = []\n",
    "\n",
    "                    for i in range(conn_mat_glos_to_goc.shape[1]): \n",
    "                        srcs = np.where(conn_mat_glos_to_goc[:,i] == 1)[0].tolist()\n",
    "                        sources2.append(srcs)\n",
    "                        tar = i + n_inputs + n_hidden_neurons\n",
    "                        targets2.append([tar]*len(srcs))\n",
    "\n",
    "                    sources = []\n",
    "                    targets = []\n",
    "\n",
    "                    for sublist in sources2:\n",
    "                        for item in sublist:\n",
    "                            sources.append(item)    \n",
    "\n",
    "                    for sublist in targets2:\n",
    "                        for item in sublist:\n",
    "                            targets.append(item)\n",
    "\n",
    "\n",
    "                    # MF -> GOC excitatory synapsis \n",
    "                    _ = simulation.AddSynapticLayer(\n",
    "                    source_list = sources,\n",
    "                    target_list = targets,\n",
    "                    param_dict = mf_goc_synapse_params,\n",
    "                    )\n",
    "\n",
    "                    #################### Connections from to GrC to GoC #################################\n",
    "\n",
    "                    hidden2 = []\n",
    "                    targets2 = []\n",
    "\n",
    "                    for i in range(conn_mat_grcs_to_goc.shape[1]): \n",
    "                        hids = np.where(conn_mat_grcs_to_goc[:,i] == 1)[0].tolist()\n",
    "                        hidden2.append([hid + n_inputs for hid in hids])\n",
    "                        tar = i + n_inputs + n_hidden_neurons\n",
    "                        targets2.append([tar]*len(hids))\n",
    "\n",
    "                    hiddens = []\n",
    "                    targets = []\n",
    "\n",
    "                    for sublist in hidden2:\n",
    "                        for item in sublist:\n",
    "                            hiddens.append(item)    \n",
    "\n",
    "                    for sublist in targets2:\n",
    "                        for item in sublist:\n",
    "                            targets.append(item)    \n",
    "\n",
    "                    # GrC -> GOC excitatory synapsis \n",
    "                    _ = simulation.AddSynapticLayer(\n",
    "                    source_list = hiddens,\n",
    "                    target_list = targets,\n",
    "                    param_dict = grc_goc_synapse_params,\n",
    "                    )\n",
    "\n",
    "                    #################### Connections from to GoC to GrC ##################################\n",
    "\n",
    "                    hidden2 = []\n",
    "                    targets2 = []\n",
    "\n",
    "                    for i in range(conn_mat_goc_to_grcs.shape[1]): \n",
    "                        hids = np.where(conn_mat_goc_to_grcs[:,i] == 1)[0].tolist()\n",
    "                        hidden2.append([hid + n_inputs for hid in hids])\n",
    "                        tar = i + n_inputs + n_hidden_neurons\n",
    "                        targets2.append([tar]*len(hids))\n",
    "\n",
    "                    hiddens = []\n",
    "                    targets = []\n",
    "\n",
    "                    for sublist in hidden2:\n",
    "                        for item in sublist:\n",
    "                            hiddens.append(item)    \n",
    "\n",
    "                    for sublist in targets2:\n",
    "                        for item in sublist:\n",
    "                            targets.append(item)    \n",
    "\n",
    "                    # GoC -> GrC inhibitory synapsis \n",
    "                    _ = simulation.AddSynapticLayer(\n",
    "                    source_list = targets,\n",
    "                    target_list = hiddens,\n",
    "                    param_dict = goc_grc_synapse_params,\n",
    "                    )\n",
    "                    \n",
    "                    ## Initializing simulation\n",
    "                    simulation.Initialize()\n",
    "\n",
    "                    dt = duration_pattern\n",
    "                    np.random.seed(seed_noise)    \n",
    "                    ## Initial time (first pattern)\n",
    "                    time = 0.0 \n",
    "                    \n",
    "                    ## Number of possible noisy inputs\n",
    "                    n_noise = round(noise*n_inputs)\n",
    "                    \n",
    "                    ## Indexes of possible noisy inputs\n",
    "                    noise_indexes = np.random.choice(range(n_inputs), n_noise, replace = False) ## indexes of the mfs that we will flip their activity\n",
    "                    \n",
    "                    ## Number of noisy inputs whose activity will be changed \n",
    "                    ## given the MF active fraction of the simulation\n",
    "                    n_active = round(fraction*len(noise_indexes))\n",
    "                    \n",
    "                    ## Indexes of noisy MFs that will be activitated\n",
    "                    active_indexes = np.random.choice(noise_indexes, n_active, replace = False)\n",
    "                    \n",
    "                    # Deleting the activity of the noisy inputs from the original spikes vectors\n",
    "                    tim = (ot0>=time) * (ot0<=(time+dt)) \n",
    "                    ot_new0 = ot0[tim]\n",
    "                    oi_new0 = oi0[tim]\n",
    "                    for elemento in noise_indexes: \n",
    "                        positions = list(np.where(oi_new0 == elemento)[0])\n",
    "                        if positions:\n",
    "                            oi_new0 = np.delete(oi_new0, positions)\n",
    "                            ot_new0 = np.delete(ot_new0, positions)\n",
    "                    \n",
    "                    ## Activating the chosen noisy inputs with the activity of the new spikes trains\n",
    "                    tim = (ot_k>=time) * (ot_k<=(time+dt)) \n",
    "                    ot_newk = ot_k[tim]\n",
    "                    oi_newk = oi_k[tim]\n",
    "                    for elemento in active_indexes: \n",
    "                        positions = list(np.where(oi_k[tim] == elemento)[0])\n",
    "                        if positions:\n",
    "                            oi_new0 = np.concatenate((oi_new0, oi_newk[positions]))\n",
    "                            ot_new0 = np.concatenate((ot_new0, ot_newk[positions]))\n",
    "\n",
    "\n",
    "                    ## Adding external spike activity (times and neuron indexes)\n",
    "                    simulation.AddExternalSpikeActivity(ot_new0, oi_new0)\n",
    "\n",
    "                    ## Running the simulation step-by-step (pattern by pattern)\n",
    "\n",
    "                    total_simulation_time = stop_simulation_at\n",
    "                    simulation_bin = duration_pattern\n",
    "\n",
    "                    j = 1\n",
    "                    for sim_time in np.arange(0.0 + simulation_bin, total_simulation_time + simulation_bin - 0.000001, simulation_bin):\n",
    "\n",
    "                        simulation.RunSimulation(sim_time)\n",
    "\n",
    "                        if j < (num_patterns):\n",
    "\n",
    "                            seed_noise += 1    \n",
    "                            np.random.seed(seed_noise)\n",
    "\n",
    "                            ## Number of possible noisy input\n",
    "                            n_noise = round(noise*n_inputs) \n",
    "                            \n",
    "                            ## Indexes of possible noisy inputs\n",
    "                            noise_indexes = np.random.choice(range(n_inputs), n_noise, replace = False) ## indexes of the mfs that we will flip their activity\n",
    "                            \n",
    "                            ## Number of noisy inputs whose activity will be changed \n",
    "                            ## given the MF active fraction of the simulation\n",
    "                            n_active = round(fraction*len(noise_indexes))\n",
    "                            \n",
    "                            ## Indexes of noisy MFs that will be activitated\n",
    "                            active_indexes = np.random.choice(noise_indexes, n_active, replace = False)\n",
    "\n",
    "                            ## Deleting the activity of the noisy inputs from the original spikes vectors\n",
    "                            tim = (ot0>=sim_time) * (ot0<=(sim_time+dt)) \n",
    "                            ot_new0 = ot0[tim]\n",
    "                            oi_new0 = oi0[tim]\n",
    "\n",
    "                            for elemento in noise_indexes: \n",
    "                                positions = list(np.where(oi_new0 == elemento)[0])\n",
    "                                if positions:\n",
    "                                    oi_new0 = np.delete(oi_new0, positions)\n",
    "                                    ot_new0 = np.delete(ot_new0, positions)\n",
    "\n",
    "                            ## Activating the chosen noisy inputs with the activity of the new spikes trains\n",
    "                            tim = (ot_k>=sim_time) * (ot_k<=(sim_time+dt)) \n",
    "                            ot_newk = ot_k[tim]\n",
    "                            oi_newk = oi_k[tim]\n",
    "\n",
    "                            for elemento in active_indexes: \n",
    "\n",
    "                                positions = list(np.where(oi_k[tim] == elemento)[0])\n",
    "\n",
    "                                if positions:\n",
    "                                    oi_new0 = np.concatenate((oi_new0, oi_newk[positions]))\n",
    "                                    ot_new0 = np.concatenate((ot_new0, ot_newk[positions]))\n",
    "\n",
    "                            # Adding external spike activity (times and neuron indexes)\n",
    "                            simulation.AddExternalSpikeActivity(ot_new0, oi_new0)\n",
    "\n",
    "                        j += 1\n",
    "\n",
    "\n",
    "                    seed_noise += 1\n",
    "\n",
    "\n",
    "                    # Retrieving output spike activity\n",
    "                    output_times, output_index = simulation.GetSpikeActivity()\n",
    "                    ot = np.array(output_times)\n",
    "                    oi = np.array(output_index)\n",
    "\n",
    "                    t_step = duration_pattern\n",
    "                    t_lower = duration_pattern - interval\n",
    "                    \n",
    "                    ## Counting number of spikes for each cell\n",
    "                    matrix = spikes_count(oi, ot, t_step, t_lower)\n",
    "\n",
    "                    ## Saving MF spikes\n",
    "                    np.savetxt('../data/spikes/seed' + str(seed) \n",
    "                            + '/sigma_' + str(sigma) \n",
    "                            + '/noise_' + str(noise)\n",
    "                            + '/mf'\n",
    "                            + '/f_mf_' + str(fraction) \n",
    "                            + '/i' + str(interval) + '_mf_s' + str(k) + '.csv', \n",
    "                            matrix[:n_inputs,:])\n",
    "\n",
    "                    ## Saving GRC spikes\n",
    "                    np.savetxt('../data/spikes/seed' + str(seed) \n",
    "                            + '/sigma_' + str(sigma) \n",
    "                            + '/noise_' + str(noise)\n",
    "                            + '/grc'\n",
    "                            + '/mf_grc_' + str(mf_grc_w) \n",
    "                            + '/mf_goc_w_' + str(mf_goc_w)\n",
    "                            + '/goc_grc_w_' + str(goc_grc_w)\n",
    "                            + '/grc_goc_w_' + str(grc_goc_w)\n",
    "                            +'/f_mf_' + str(fraction) \n",
    "                            + '/i' + str(interval) + '_grc_s' + str(k) + '.csv', \n",
    "                               matrix[n_inputs:(n_inputs + n_hidden_neurons),:])\n",
    "\n",
    "                    del matrix, ot, oi, ot_k, oi_k\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
